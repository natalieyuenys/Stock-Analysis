{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac6b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import new_sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e580a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income = pd.read_csv('data/income_statement.csv')\n",
    "df_balance = pd.read_csv('data/balance_sheet.csv')\n",
    "df_cash_flow = pd.read_csv('data/cash_flow_statement.csv')   \n",
    "df_earnings = pd.read_csv('data/earnings.csv')   \n",
    "df_overview = pd.read_csv('data/company_overview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d5ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income['fiscalDateEnding'] = pd.to_datetime(df_income['fiscalDateEnding'])\n",
    "df_balance['fiscalDateEnding'] = pd.to_datetime(df_balance['fiscalDateEnding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5499d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income = df_income.sort_values(by=['symbol', 'fiscalDateEnding'])\n",
    "df_balance = df_balance.sort_values(by=['symbol', 'fiscalDateEnding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d66ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in df_income['symbol'].unique():\n",
    "    income_data = df_income[df_income['symbol'] == symbol]\n",
    "    balance_data = df_balance[df_balance['symbol'] == symbol]\n",
    "    overview_data = df_overview[df_overview['symbol'] == symbol]\n",
    "    \n",
    "    # Leverage Ratios\n",
    "    debt_to_equity  = balance_data['totalLiabilities'].tail(1).values[0] / balance_data['totalShareholderEquity'].tail(1).values[0]\n",
    "    debt_to_assets = balance_data['totalLiabilities'].tail(1).values[0] / balance_data['totalAssets'].tail(1).values[0]\n",
    "    interest_coverage = income_data['ebitda'].tail(1).values[0] / income_data['interestExpense'].tail(1).values[0]\n",
    "\n",
    "    # Liquidity Measures\n",
    "    current_ratio = balance_data['totalCurrentAssets'].tail(1).values[0] / balance_data['totalCurrentLiabilities'].tail(1).values[0]\n",
    "    quick_ratio = (balance_data['totalCurrentAssets'].tail(1).values[0] - balance_data['inventory'].tail(1).values[0]) / balance_data['totalCurrentLiabilities'].tail(1).values[0]\n",
    "    cash_ratio = balance_data['cashAndCashEquivalentsAtCarryingValue'].tail(1).values[0] / balance_data['totalCurrentLiabilities'].tail(1).values[0]\n",
    "\n",
    "    # Profitability Metrics\n",
    "    ttm_net_income = sum(income_data['netIncome'].tail(4))\n",
    "    ttm_revenue = sum(income_data['totalRevenue'].tail(4))\n",
    "    avg_shareholders_equity = (balance_data['totalShareholderEquity'].tail(5)).mean()\n",
    "    avg_assets = (balance_data['totalAssets'].tail(5)).mean()\n",
    "\n",
    "    roe = ttm_net_income / avg_shareholders_equity\n",
    "    roa = ttm_net_income / avg_assets\n",
    "    profit_margin = ttm_net_income / ttm_revenue\n",
    "\n",
    "    # Logarithmic Transformations\n",
    "    ln_market_cap = np.log(overview_data['MarketCapitalization'].tail(1).values[0])\n",
    "    ln_total_assets = np.log(balance_data['totalAssets'].tail(1).values[0])    \n",
    "\n",
    "    # Growth Metrics\n",
    "    revenue_previous = sum(income_data['totalRevenue'].tail(8).values[0:4]) \n",
    "    revenue_growth = ((ttm_revenue - revenue_previous) / revenue_previous)\n",
    "\n",
    "    earnings_previous = sum(income_data['netIncome'].tail(8).values[0:4])\n",
    "    earnings_growth = ((ttm_net_income - earnings_previous) / earnings_previous)\n",
    "\n",
    "    asset_previous = balance_data['totalAssets'].tail(2).values[0] \n",
    "    asset_growth = ((balance_data['totalAssets'].tail(1).values[0] - asset_previous) / asset_previous)\n",
    "    \n",
    "    indutry_dummies = pd.get_dummies(overview_data['Industry'], prefix='industry', drop_first=True)    \n",
    "\n",
    "    # Add results to overview DataFrame\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'debt_to_equity'] = debt_to_equity\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'debt_to_assets'] = debt_to_assets\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'interest_coverage'] = interest_coverage\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'current_ratio'] = current_ratio\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'quick_ratio'] = quick_ratio\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'cash_ratio'] =  cash_ratio      \n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'ROE'] = roe\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'ROA'] = roa\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'profit_margin'] = profit_margin\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'ln_market_cap'] = ln_market_cap\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'ln_total_assets'] = ln_total_assets       \n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'revenue_growth'] = revenue_growth\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'earnings_growth'] = earnings_growth\n",
    "    df_overview.loc[df_overview['symbol'] == symbol, 'asset_growth'] = asset_growth \n",
    "    for col in indutry_dummies.columns:\n",
    "        df_overview.loc[df_overview['symbol'] == symbol, col] = indutry_dummies[col].values[0]    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de559bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro = pd.read_csv('data/macro_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcff4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro['date'] = pd.to_datetime(df_macro['date'])\n",
    "df_macro = df_macro.replace(\".\", np.nan) \n",
    "df_macro = df_macro.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36e13299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro['value'] = pd.to_numeric(df_macro['value'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f64e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10y_treasury = df_macro[(df_macro['function'] == 'Treasury_Yield')& (df_macro['maturity']==10.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce1e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = pd.DataFrame({'date':pd.date_range(start='2024-01-01', end='2025-07-02')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93a81c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df_date.merge(df_10y_treasury, how='left', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e50c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.rename(columns={'value': '10y_yield'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0136f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['10y_yield'] = df_daily['10y_yield'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd8d0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['week'] = (df_daily['date'] - pd.Timedelta(days=3)).dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c15937c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['week'] = df_daily['date'].dt.year.astype(str) + '-' + df_daily['week'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcfd9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df_daily[df_daily['week']!= '2024-52']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbb9d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price = pd.read_csv('data/tech_stock_daily_price.csv')\n",
    "df_price['Date'] = pd.to_datetime(df_price['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43d436ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('ALPHA_VANTAGE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69067563",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=[\n",
    "    'Ticker', \n",
    "    'Intercept', \n",
    "    'Beta_10Y_Treasury', \n",
    "    'Beta_SP500', \n",
    "    'R_squared'\n",
    "])\n",
    "\n",
    "for ticker in df_price['ticker'].unique():\n",
    "    if ticker!='SPY':\n",
    "        price_data = df_price[df_price['ticker'] == ticker]\n",
    "        price_data = price_data.rename(columns={'Date': 'date', 'Close': 'close'})\n",
    "        price_data['date'] = pd.to_datetime(price_data['date'])\n",
    "\n",
    "        SPY_500 = df_price[df_price['ticker'] == 'SPY']\n",
    "        SPY_500 = SPY_500.rename(columns={'Date': 'date', 'Close': 'SPY_close'})\n",
    "        SPY_500['date'] = pd.to_datetime(SPY_500['date'])\n",
    "\n",
    "        # Merge with daily yield data\n",
    "        merged_data = pd.merge(df_daily, price_data, on='date', how='left')\n",
    "        merged_data['close'] = merged_data['close'].fillna(method='ffill')\n",
    "\n",
    "        merged_data = pd.merge(merged_data, SPY_500, on='date', how='left')\n",
    "        merged_data['SPY_close'] = merged_data['SPY_close'].fillna(method='ffill')\n",
    "\n",
    "        # Calculate weekly average close price\n",
    "        merged_data['week'] = merged_data['date'].dt.year.astype(str) + '-' + merged_data['date'].dt.isocalendar().week.astype(str)\n",
    "        merged_data = merged_data.groupby('week')[['close','10y_yield','SPY_close']].mean().reset_index()\n",
    "        merged_data.rename(columns={'close': 'weekly_avg_close','10y_yield': 'weekly_avg_yield','SPY_close':'weekly_SPY_close'}, inplace=True)\n",
    "        merged_data['change_weekly_avg_close'] = merged_data['weekly_avg_close'].pct_change().fillna(0)  \n",
    "        merged_data['change_weekly_avg_yield'] = merged_data['weekly_avg_yield'].pct_change().fillna(0)\n",
    "        merged_data['change_weekly_SPY_close'] = merged_data['weekly_SPY_close'].pct_change().fillna(0)\n",
    "\n",
    "        # Fit regression: stock_return ~ change_10Y_Treasury + sp500_return\n",
    "        X = merged_data[['change_weekly_avg_yield', 'change_weekly_SPY_close']]\n",
    "        y = merged_data['change_weekly_avg_close']\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "\n",
    "        new_row = pd.DataFrame([{\n",
    "        'Ticker': ticker,\n",
    "        'Intercept': model.intercept_,\n",
    "        'Beta_10Y_Treasury': model.coef_[0],\n",
    "        'Beta_SP500': model.coef_[1],\n",
    "        'R_squared': model.score(X, y)\n",
    "        }])\n",
    "\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb279c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector = pd.read_csv('data/sector_data.csv')\n",
    "df_sector = df_sector.rename(columns={'Symbol': 'Ticker', 'Name': 'Company'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2251598",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.merge(df_sector, how='left', on='Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fba4c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f'data/SP500_senstitivity_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
